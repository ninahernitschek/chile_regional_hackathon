{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33d96022-6e30-4931-b70f-1d3aee0745e0",
   "metadata": {},
   "source": [
    "# Notebook 2: Reading Data / Notebook 2: Lectura de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c7ce69-b1fa-4046-ad3a-868aa6b3404f",
   "metadata": {},
   "source": [
    "Welcome! The main goal of this notebook is to read the Cubeset data and explore its characteristics.\n",
    "\n",
    "\n",
    " <hr style=\"border:2px solid gray\">\n",
    " \n",
    "¡Bienvenido! El objetivo principal de este cuaderno es leer los datos de Cubeset y explorar sus características.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5059112-490b-4c53-9c84-489bd09d5316",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9d95d4-1c54-40dc-9546-e9f9b95ee932",
   "metadata": {},
   "source": [
    "The dataset we will be working with contains five classes, described as follows:\n",
    "- **Blurry**: Data captured while the satellite is in motion, resulting in blurred images.\n",
    "- **Corrupt**: Images with defects from improper camera priming or stray light.\n",
    "- **Missing Data**: Images with partial or complete data loss.\n",
    "- **Noisy**: Images over-saturated with noise from radiation or other sources.\n",
    "- **Priority**: Clear images suitable for scientific analysis on the ground.\n",
    "\n",
    "\n",
    " <hr style=\"border:2px solid gray\">\n",
    " \n",
    " \n",
    "El conjunto de datos con el que trabajaremos contiene cinco clases, que se describen a continuación:\n",
    "- **Borrosa** (Blurry): Datos capturados mientras el satélite está en movimiento, lo que da lugar a imágenes borrosas.\n",
    "- **Corruptas** (Corrupt): Imágenes con defectos debidos a un cebado incorrecto de la cámara o a luz parásita.\n",
    "- **Datos perdidos** (Missing data): Imágenes con pérdida parcial o total de datos.\n",
    "- **Ruido** (Noisy): Imágenes sobresaturadas de ruido por radiación u otras fuentes.\n",
    "- **Prioridad** (Priority): Imágenes nítidas aptas para el análisis científico sobre el terreno.\n",
    "\n",
    "(En el código, utilizaremos el términos ingléses.\n",
    "También mantenemos los comentarios del código en inglés después de la primera introducción. Esto le ayudará a preparar su presentación, que debe ser en inglés. Si es necesario, comuníquese con sus compañeros de equipo y utilice un traductor en línea como www.deepl.com.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288bdedc-c265-4079-a8f4-9cb7bfbcd000",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6448f8f6-21d5-4af4-bccd-45990ac01ada",
   "metadata": {},
   "source": [
    "#### Importing libraries / Importar bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdb94d2d-f310-413b-b718-e52f41ad5031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A custom function that reads .jpg images from a folder and returns them as a stacked NumPy array.\n",
    "# Una función personalizada que lee imágenes .jpg de una carpeta y las devuelve como un array NumPy apilado.\n",
    "from source.pre import read_images_from_folder\n",
    "\n",
    "# Importing the 'os' module for interacting with the operating system, such as handling file paths.\n",
    "# Importar el módulo 'os' para interactuar con el sistema operativo, como el manejo de rutas de archivos.\n",
    "import os  \n",
    "\n",
    "# Importing 'ProcessPoolExecutor' for parallel execution using multiple processors.\n",
    "# Importación de 'ProcessPoolExecutor' para ejecución paralela utilizando múltiples procesadores.\n",
    "from concurrent.futures import ProcessPoolExecutor  \n",
    "\n",
    "# Importing Matplotlib for creating visualizations and plots.\n",
    "# Importación de Matplotlib para crear visualizaciones y gráficos.\n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "# Importing the 'random' module for generating random numbers and making random selections.\n",
    "# Importar el módulo 'random' para generar números aleatorios y hacer selecciones aleatorias.\n",
    "import random  \n",
    "\n",
    "# Importing NumPy, a library for numerical operations, used here for handling and manipulating image data arrays.\n",
    "# Importación de NumPy, una biblioteca para operaciones numéricas, utilizada aquí para manejar y manipular matrices de datos de imagen.\n",
    "import numpy as np  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ce9fcc-7d34-4030-913f-87ea5da2da50",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = [\"Blurry\", \"Corrupt\", \"Missing_Data\", \"Noisy\", \"Priority\"] # The 5 classes of our data\n",
    "base_dir = \"data/\" # Where the data sets\n",
    "images_by_class = {} # Dictionary to store images by class\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b618e84a-8427-49e1-a2bf-0369900d2000",
   "metadata": {},
   "source": [
    "#### Read images from each folder/class / Leer imágenes de cada carpeta/tipo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b26c061-a218-4b41-a62a-7b5844f76fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read images from a specific folder\n",
    "# This function is designed to be used with ProcessPoolExecutor for parallel processing.\n",
    "# It takes a folder name, constructs the full path, reads all images, and returns both the folder name and the images.\n",
    "def process_folder(folder):\n",
    "    folder_path = os.path.join(base_dir, folder)\n",
    "    images = read_images_from_folder(folder_path)\n",
    "    return folder, images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d312d932-66e9-4a77-966f-df7e2f632100",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1abd19a-4d86-4b96-be52-ee08963cf071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ProcessPoolExecutor to parallelize the folder processing\n",
    "with ProcessPoolExecutor(max_workers=5) as executor:\n",
    "    results = executor.map(process_folder, folders)\n",
    "\n",
    "# Collect the results\n",
    "for folder, images in results:\n",
    "    images_by_class[folder] = images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5886fb9a-a6ee-4fca-b5ad-d80d5f089e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_images = 0  # Initialize a counter for the total number of images\n",
    "\n",
    "for folder, images in images_by_class.items():\n",
    "    num_images = len(images)\n",
    "    print(f\"Class '{folder}': {num_images} images read.\")\n",
    "    total_images += num_images  # Add the number of images in the current class to the total\n",
    "\n",
    "# Print the total number of images for all classes\n",
    "print(f\"Total images read across all classes: {total_images}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1ebfbe-24d6-4093-90e3-11a214c1a514",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d18c67-2fc6-4926-94b2-d4024c034e1c",
   "metadata": {},
   "source": [
    "### Visualization / Visualización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77e56e4-4dd0-44e1-94d2-5ef6c0b499bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "# Assuming images_by_class is your dictionary\n",
    "# where keys are class names and values are numpy arrays of images\n",
    "\n",
    "for folder, images in images_by_class.items():    \n",
    "    # Ensure we have at least 5 images\n",
    "    num_images_to_display = min(5, len(images))\n",
    "    \n",
    "    # Randomly select 5 images\n",
    "    random_indices = random.sample(range(len(images)), num_images_to_display)\n",
    "    selected_images = images[random_indices] / 255.0\n",
    "\n",
    "    # Plot the selected images\n",
    "    fig, axes = plt.subplots(1, num_images_to_display, figsize=(20, 4))\n",
    "    fig.suptitle(f'Class: {folder}', fontsize=16)\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    \n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.imshow(selected_images[i])\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.show()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b099a4-1a15-4a54-9d04-f2a8cbd7aa46",
   "metadata": {},
   "source": [
    "The images in the dataset appear to have distinct visual characteristics that make them easy to classify by eye. For example, “Blurry,” “Corrupt” and “Missing Data” images each have unique visual patterns and anomalies that differentiate them from one another. Given these clear differences, we can reasonably expect that machine learning models would also be able to classify these images with high accuracy, as the features that distinguish each class are visually pronounced and easily identifiable.\n",
    "\n",
    "\n",
    " <hr style=\"border:2px solid gray\">\n",
    " \n",
    "Las imágenes del conjunto de datos parecen tener características visuales distintas que facilitan su clasificación a simple vista. Por ejemplo, las imágenes «Blurry», «Corrupt» y «Missing Data» presentan patrones visuales únicos y anomalías que las diferencian unas de otras. Dadas estas claras diferencias, podemos esperar razonablemente que los modelos de aprendizaje automático también sean capaces de clasificar estas imágenes con gran precisión, ya que las características que distinguen cada clase son visualmente pronunciadas y fácilmente identificables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9840b4f-08b2-4e59-a324-a15342731de2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d88a0bb-fbf8-43ac-a025-8941eb053dc8",
   "metadata": {},
   "source": [
    "### Pre-processing / Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c83ed5-2bae-48ef-8a69-b3680d3a0cbc",
   "metadata": {},
   "source": [
    "#### Converting Images and Labels to NumPy Arrays /  Conversión de imágenes y etiquetas en arrays NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807b379e-200a-4f27-9ad3-112fa73c3d46",
   "metadata": {},
   "source": [
    "Now we save the data into a NumPy array for easier use in machine learning, and to realise that we can follow these steps:\n",
    "\n",
    "* Combine All Images and Labels: It gathers all images and their corresponding labels into two lists.\n",
    "* Convert to NumPy Arrays: It converts these lists into NumPy arrays, which are easier to handle for machine learning tasks.\n",
    "\n",
    "\n",
    " <hr style=\"border:2px solid gray\">\n",
    " \n",
    "\n",
    "\n",
    "Ahora guardamos los datos en un array NumPy para facilitar su uso en aprendizaje automático, y para realizarlo podemos seguir los siguientes pasos:\n",
    "\n",
    "* Combina todas las imágenes y etiquetas: Reúne todas las imágenes y sus correspondientes etiquetas en dos listas.\n",
    "* Convertir a Arrays NumPy: Convierte estas listas en arrays NumPy, más fáciles de manejar para tareas de aprendizaje automático.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c62768-0b63-49eb-8630-e3e445ed87ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize lists to hold all images and labels\n",
    "all_images = []\n",
    "all_labels = []\n",
    "\n",
    "# Iterate through the images_by_class dictionary to collect images and their labels\n",
    "for label, images in images_by_class.items():\n",
    "    all_images.extend(images)  # Add all images to the list\n",
    "    all_labels.extend([label] * len(images))  # Add the corresponding label for each image\n",
    "\n",
    "\n",
    "\n",
    "# Generate random indices for 12,000 samples\n",
    "indices = np.random.choice(len(all_images), size=12000, replace=False)\n",
    "\n",
    "# Convert the lists to NumPy arrays\n",
    "all_images_np = np.array(all_images)[indices] # Select random indices for 12,000 samples to downsize the data for memory constarins\n",
    "all_labels_np = np.array(all_labels)[indices] # Select random indices for 12,000 samples to downsize the data for memory constarins\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb75ccd-0fcf-4de4-a230-6747ec7e232d",
   "metadata": {},
   "source": [
    "#### Counting the labels / Contar las etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d61764-a7a0-4f54-9603-eeedb4aa197d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming all_labels_np contains the labels after selecting 12,000 samples\n",
    "unique_labels, label_counts = np.unique(all_labels_np, return_counts=True)\n",
    "\n",
    "# Print the counts of each label\n",
    "for label, count in zip(unique_labels, label_counts):\n",
    "    print(f\"Label {label}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b16bb2-c26e-4625-842f-8231ed6689ff",
   "metadata": {},
   "source": [
    "#### Encoding the Labels / Codificación de las etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f35996-275d-4729-90f4-7f14c5c9a421",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "all_labels_encoded = label_encoder.fit_transform(all_labels_np)\n",
    "\n",
    "print(\"Original Labels:\", all_labels_np)\n",
    "print(\"Encoded Labels:\", all_labels_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53940c7c-b177-44fa-a4a7-8265fa0a346f",
   "metadata": {},
   "source": [
    "#### Shuffling and splitting the data / Barajar y dividir los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563ab8fa-f19d-469c-8567-c30950d575fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  # Importing train_test_split for splitting data into training and testing sets\n",
    "\n",
    "# Split the data: 60% training, 40% test (do not change those values for results comparisons)\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(all_images_np, all_labels_encoded, test_size=0.2, random_state=42, shuffle=True)\n",
    "print(f\"Training data: {len(train_images)} images\")\n",
    "print(f\"Testing data: {len(test_images)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870d4bda-0ca6-40cb-bcf4-7fd24ef854ec",
   "metadata": {},
   "source": [
    "#### Saving the data / Guardar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf7b389-acca-4289-a2d9-7ed1bc574169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the combined images and labels arrays to disk for future use\n",
    "np.save('train_images.npy', train_images)\n",
    "np.save('test_images.npy', test_images)\n",
    "np.save('train_labels.npy', train_labels)\n",
    "np.save('test_labels.npy', test_labels)\n",
    "\n",
    "print(\"Data saved successfully as NumPy arrays.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f5a47c-b6b0-4948-ab8f-0f6b0db0530f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40f94df-fad7-4384-8f39-07c6ea2a42f8",
   "metadata": {},
   "source": [
    "### Finally, removing data from memory / Por último, eliminar datos de la memoria\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd31cb4-ea77-45bf-86ac-bf1c5e7510e6",
   "metadata": {},
   "source": [
    "**⚠️ Important Notice**: Since this code is being executed in a shared environment (ilifu), freeing up memory is crucial to ensure efficient resource usage. By removing unused data, it helps prevent memory bottlenecks that could affect not only your work but also the performance of other users relying on the shared hardware. This is especially important when working with large datasets (like in our case), as excessive memory usage can slow down the overall system and reduce availability for others using the same resources.\n",
    "\n",
    "**Make sure to follow this same practice when you develop your own pipeline during the hackathon to optimize performance and resource allocation.**\n",
    "\n",
    "\n",
    "\n",
    " <hr style=\"border:2px solid gray\">\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "**⚠️ Aviso importante**: Dado que este código está siendo ejecutado en un entorno compartido (ilifu), liberar memoria es crucial para asegurar un uso eficiente de los recursos. Al eliminar los datos no utilizados, ayuda a prevenir cuellos de botella de memoria que podrían afectar no sólo a su trabajo, sino también el rendimiento de otros usuarios que dependen del hardware compartido. Esto es especialmente importante cuando se trabaja con grandes conjuntos de datos (como en nuestro caso), ya que el uso excesivo de memoria puede ralentizar el sistema en general y reducir la disponibilidad para otros que utilizan los mismos recursos.\n",
    "\n",
    "**Asegúrate de seguir esta misma práctica cuando desarrolles tu propio pipeline durante el hackathon para optimizar el rendimiento y la asignación de recursos.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919afa30-eff6-4a3c-b670-47c3675f0cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# Remove the data from memory\n",
    "del train_images, test_images, train_labels, test_labels, all_images_np, all_labels_np, all_labels_encoded, all_labels, all_images, total_images, images_by_class\n",
    "\n",
    "# Force garbage collection to free up memory\n",
    "gc.collect()\n",
    "\n",
    "print(\"Data removed from memory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b7b16d-5c01-470f-bd3c-fc2b9db0d492",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159bffc2-f9fd-405b-a934-7947a1939059",
   "metadata": {},
   "source": [
    "**⚠️ When you are done, make sure to restart the notebooks**\n",
    "\n",
    "\n",
    " <hr style=\"border:2px solid gray\">\n",
    " \n",
    "**⚠️ Cuando hayas terminado, asegúrate de reiniciar los Notebooks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a9fc6e-470c-4d2a-b526-4308e0be5071",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
